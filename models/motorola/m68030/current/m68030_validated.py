#!/usr/bin/env python3
"""
M68030 Grey-Box Queueing Model
===============================

Architecture: Cache/RISC Architecture (1983-1988)
Queueing Model: Cache hierarchy + pipeline network

Features:
  - On-chip instruction cache
  - Deep pipeline (5+ stages)
  - Load/store architecture
  - Register windows or large register files
  - Single-cycle execution goal

Generated by era_architecture_fix.py
Date: 2026-01-27

Note: This is a TEMPLATE. Customize timing values based on:
  - Original datasheet specifications
  - Cycle-accurate emulator validation (MAME, VICE, etc.)
  - WikiChip/Wikipedia technical specifications
"""

from dataclasses import dataclass
from typing import Dict, List, Any, Optional

# Import from common (adjust path as needed)
try:
    from common.base_model import BaseProcessorModel, InstructionCategory, WorkloadProfile, AnalysisResult, CacheConfig
except ImportError:
    # Fallback definitions if common not available
    from dataclasses import dataclass
    
    @dataclass
    class InstructionCategory:
        name: str
        base_cycles: float
        memory_cycles: float = 0
        description: str = ""
        @property
        def total_cycles(self): return self.base_cycles + self.memory_cycles
    

    @dataclass
    class CacheConfig:
        has_cache: bool = False
        l1_latency: float = 1.0
        l1_hit_rate: float = 0.95
        l2_latency: float = 10.0
        l2_hit_rate: float = 0.90
        has_l2: bool = False
        dram_latency: float = 50.0
        def effective_memory_penalty(self):
            if not self.has_cache: return 0.0
            l1_miss = 1.0 - self.l1_hit_rate
            if self.has_l2:
                l2_miss = 1.0 - self.l2_hit_rate
                return l1_miss * (self.l2_hit_rate * (self.l2_latency - self.l1_latency) + l2_miss * (self.dram_latency - self.l1_latency))
            return l1_miss * (self.dram_latency - self.l1_latency)


    @dataclass
    class WorkloadProfile:
        name: str
        category_weights: Dict[str, float]
        description: str = ""
    
    @dataclass
    class AnalysisResult:
        processor: str
        workload: str
        ipc: float
        cpi: float
        ips: float
        bottleneck: str
        utilizations: Dict[str, float]
        base_cpi: float = 0.0
        correction_delta: float = 0.0

        @classmethod
        def from_cpi(cls, processor, workload, cpi, clock_mhz, bottleneck, utilizations, base_cpi=None, correction_delta=0.0):
            ipc = 1.0 / cpi
            ips = clock_mhz * 1e6 * ipc
            return cls(processor, workload, ipc, cpi, ips, bottleneck, utilizations, base_cpi if base_cpi is not None else cpi, correction_delta)
    
class BaseProcessorModel:
        def get_corrections(self):
            return getattr(self, 'corrections', {})
        def set_corrections(self, corrections):
            self.corrections = corrections
        def compute_correction_delta(self, workload='typical'):
            profile = self.workload_profiles.get(workload, list(self.workload_profiles.values())[0])
            return sum(self.corrections.get(c, 0) * profile.category_weights.get(c, 0) for c in self.corrections)
        def compute_residuals(self, measured_cpi_dict):
            return {w: self.analyze(w).cpi - m for w, m in measured_cpi_dict.items()}
        def compute_loss(self, measured_cpi_dict):
            residuals = self.compute_residuals(measured_cpi_dict)
            return sum(r**2 for r in residuals.values()) / len(residuals) if residuals else 0
        def get_parameters(self):
            params = {}
            for c, cat in self.instruction_categories.items():
                params[f'cat.{c}.base_cycles'] = cat.base_cycles
            for c, v in self.corrections.items():
                params[f'cor.{c}'] = v
            return params
        def set_parameters(self, params):
            for k, v in params.items():
                if k.startswith('cat.') and k.endswith('.base_cycles'):
                    c = k[4:-12]
                    if c in self.instruction_categories:
                        self.instruction_categories[c].base_cycles = v
                elif k.startswith('cor.'):
                    c = k[4:]
                    self.corrections[c] = v
        def get_parameter_bounds(self):
            bounds = {}
            for c, cat in self.instruction_categories.items():
                bounds[f'cat.{c}.base_cycles'] = (0.1, cat.base_cycles * 5)
            for c in self.corrections:
                bounds[f'cor.{c}'] = (-50, 50)
            return bounds
        def get_parameter_metadata(self):
            return {k: {'type': 'category' if k.startswith('cat.') else 'correction'} for k in self.get_parameters()}
        def get_instruction_categories(self):
            return self.instruction_categories
        def get_workload_profiles(self):
            return self.workload_profiles
        def validate(self):
            return {'tests': [], 'passed': 0, 'total': 0, 'accuracy_percent': None}

class M68030Model(BaseProcessorModel):
    """
    M68030 Grey-Box Queueing Model
    
    Architecture: Cache/RISC (Era: 1983-1988)
    - 5-stage pipeline
    - 4KB instruction cache
    - 0.256KB D-cache
    - Standard branches
    """
    
    # Processor specifications
    name = "M68030"
    manufacturer = "Motorola"
    year = 1987
    clock_mhz = 16.0
    transistor_count = 273000
    data_width = 32
    address_width = 32
    
    def __init__(self):
        # Pipeline configuration
        self.pipeline_depth = 5
        
        # Cache configuration
        self.icache_size_kb = 4
        self.icache_hit_rate = 0.95
        self.dcache_size_kb = 4
        self.dcache_hit_rate = 0.9
        self.memory_latency = 10
        
        # Branch handling
        self.has_delayed_branch = False
        self.branch_penalty = 2
        
        # Instruction categories (RISC: most are single-cycle)
        self.instruction_categories = {
            'alu': InstructionCategory('alu', 1, 0, "ALU operations (single-cycle)"),
            'load': InstructionCategory('load', 1, 1, "Load from memory"),
            'store': InstructionCategory('store', 1, 0, "Store to memory"),
            'branch': InstructionCategory('branch', 1, 0, "Branch (+ penalty if taken)"),
            'multiply': InstructionCategory('multiply', 10, 0, "Multiply"),
            'divide': InstructionCategory('divide', 30, 0, "Divide"),
            'fp_single': InstructionCategory('fp_single', 3, 0, "FP single precision"),
            'fp_double': InstructionCategory('fp_double', 6, 0, "FP double precision"),
        }
        
        # Workload profiles
        self.workload_profiles = {
            'typical': WorkloadProfile('typical', {
                'alu': 0.40, 'load': 0.20, 'store': 0.10,
                'branch': 0.15, 'multiply': 0.05, 'divide': 0.02,
                'fp_single': 0.05, 'fp_double': 0.03,
            }, "Typical RISC workload"),
            'compute': WorkloadProfile('compute', {
                'alu': 0.60, 'load': 0.12, 'store': 0.06,
                'branch': 0.10, 'multiply': 0.02, 'divide': 0.01,
                'fp_single': 0.05, 'fp_double': 0.04,
            }, "Compute-intensive"),
            'memory': WorkloadProfile('memory', {
                'alu': 0.22, 'load': 0.35, 'store': 0.20,
                'branch': 0.15, 'multiply': 0.01, 'divide': 0.005,
                'fp_single': 0.03, 'fp_double': 0.025,
            }, "Memory-intensive"),
            'control': WorkloadProfile('control', {
                'alu': 0.32, 'load': 0.17, 'store': 0.10,
                'branch': 0.35, 'multiply': 0.01, 'divide': 0.005,
                'fp_single': 0.03, 'fp_double': 0.015,
            }, "Control-flow intensive"),
        }

        # Correction terms for system identification (initially zero)
        self.corrections = {
            'alu': 3.003481,
            'branch': 5.000000,
            'divide': 8.607405,
            'fp_double': 5.999916,
            'fp_single': 5.000000,
            'load': 5.000000,
            'multiply': -9.998481,
            'store': 5.000000
        }

        # Cache configuration for memory hierarchy modeling
        self.cache_config = CacheConfig(
            has_cache=True,
            l1_latency=1.0,
            l1_hit_rate=0.9000,
            dram_latency=8.0,
        )
        self.memory_categories = ['load', 'store']

    def analyze(self, workload: str = 'typical') -> AnalysisResult:
        """Analyze using Cache/RISC model"""
        profile = self.workload_profiles.get(workload, self.workload_profiles['typical'])

        # Apply cache miss penalty to memory-accessing categories
        if hasattr(self, 'cache_config') and self.cache_config and self.cache_config.has_cache:
            penalty = self.cache_config.effective_memory_penalty()
            for cat_name in getattr(self, 'memory_categories', []):
                if cat_name in self.instruction_categories:
                    self.instruction_categories[cat_name].memory_cycles = penalty

        
        # Base CPI (RISC goal: 1.0)
        base_cpi = 1.0
        
        # I-cache miss penalty
        icache_miss_cpi = (1 - self.icache_hit_rate) * self.memory_latency
        
        # D-cache miss penalty
        load_weight = profile.category_weights.get('load', 0.20)
        store_weight = profile.category_weights.get('store', 0.10)
        mem_fraction = load_weight + store_weight
        
        if self.dcache_size_kb > 0:
            dcache_miss_cpi = mem_fraction * (1 - self.dcache_hit_rate) * self.memory_latency
        else:
            dcache_miss_cpi = load_weight * self.memory_latency * 0.3
        
        # Branch penalty
        branch_weight = profile.category_weights.get('branch', 0.15)
        taken_rate = 0.6  # Fraction of branches taken
        if self.has_delayed_branch:
            branch_cpi = branch_weight * taken_rate * 0.2  # Some unfilled delay slots
        else:
            branch_cpi = branch_weight * taken_rate * self.branch_penalty
        
        # Multi-cycle instructions
        mult_cpi = profile.category_weights.get('multiply', 0) * (10 - 1)
        div_cpi = profile.category_weights.get('divide', 0) * (30 - 1)
        
        base_cpi_total = base_cpi + icache_miss_cpi + dcache_miss_cpi + branch_cpi + mult_cpi + div_cpi

        # Apply correction terms from system identification
        correction_delta = sum(
            self.corrections.get(cat_name, 0.0) * weight
            for cat_name, weight in profile.category_weights.items()
        )
        corrected_cpi = base_cpi_total + correction_delta

        ipc = 1.0 / corrected_cpi
        ips = self.clock_mhz * 1e6 * ipc

        # Bottleneck
        penalties = {'icache': icache_miss_cpi, 'dcache': dcache_miss_cpi, 'branch': branch_cpi}
        bottleneck = max(penalties, key=penalties.get) if max(penalties.values()) > 0.1 else 'balanced'

        return AnalysisResult.from_cpi(
            processor=self.name,
            workload=workload,
            cpi=corrected_cpi,
            clock_mhz=self.clock_mhz,
            bottleneck=bottleneck,
            utilizations=penalties,
            base_cpi=base_cpi_total,
            correction_delta=correction_delta
        )
    
    def validate(self) -> Dict[str, Any]:
        """Run validation tests"""
        tests = []

        # Test 1: CPI within expected range
        result = self.analyze('typical')
        expected_cpi = 3.0  # M68030 target CPI
        cpi_error = abs(result.cpi - expected_cpi) / expected_cpi * 100
        tests.append({
            'name': 'CPI accuracy',
            'passed': cpi_error < 5.0,
            'expected': f'{expected_cpi} +/- 5%',
            'actual': f'{result.cpi:.2f} ({cpi_error:.1f}% error)'
        })

        # Test 2: Workload weights sum to 1.0
        for profile_name, profile in self.workload_profiles.items():
            weight_sum = sum(profile.category_weights.values())
            tests.append({
                'name': f'Weights sum ({profile_name})',
                'passed': 0.99 <= weight_sum <= 1.01,
                'expected': '1.0',
                'actual': f'{weight_sum:.2f}'
            })

        # Test 3: All cycle counts are positive and reasonable
        for cat_name, cat in self.instruction_categories.items():
            cycles = cat.total_cycles
            tests.append({
                'name': f'Cycle count ({cat_name})',
                'passed': 0.5 <= cycles <= 200.0,
                'expected': '0.5-200 cycles',
                'actual': f'{cycles:.1f}'
            })

        # Test 4: IPC is in valid range
        tests.append({
            'name': 'IPC range',
            'passed': 0.05 <= result.ipc <= 1.5,
            'expected': '0.05-1.5',
            'actual': f'{result.ipc:.3f}'
        })

        # Test 5: All workloads produce valid results
        for workload in self.workload_profiles.keys():
            try:
                r = self.analyze(workload)
                valid = r.cpi > 0 and r.ipc > 0 and r.ips > 0
                tests.append({
                    'name': f'Workload analysis ({workload})',
                    'passed': valid,
                    'expected': 'Valid CPI/IPC/IPS',
                    'actual': f'CPI={r.cpi:.2f}' if valid else 'Invalid'
                })
            except Exception as e:
                tests.append({
                    'name': f'Workload analysis ({workload})',
                    'passed': False,
                    'expected': 'No error',
                    'actual': str(e)
                })

        passed = sum(1 for t in tests if t['passed'])
        return {
            'tests': tests,
            'passed': passed,
            'total': len(tests),
            'accuracy_percent': 100.0 - cpi_error
        }
    
    def get_instruction_categories(self) -> Dict[str, InstructionCategory]:
        return self.instruction_categories
    
    def get_workload_profiles(self) -> Dict[str, WorkloadProfile]:
        return self.workload_profiles
